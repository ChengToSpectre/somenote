
# 1.爬虫的过程分析
# 当人类去访问一个网页时，是如何进行的？
# 　　①打开浏览器，输入要访问的网址，发起请求。
# 　　②等待服务器返回数据，通过浏览器加载网页。
# 　　③从网页中找到自己需要的数据（文本、图片、文件等等）。
# 　　④保存自己需要的数据。

# 对于爬虫，也是类似的。它模仿人类请求网页的过程，但是又稍有不同。
# 　　首先，对应于上面的①和②步骤，我们要利用python实现请求一个网页的功能。
# 　　其次，对应于上面的③步骤，我们要利用python实现解析请求到的网页的功能。
# 　　最后，对于上面的④步骤，我们要利用python实现保存数据的功能。
# 　　因为是讲一个简单的爬虫嘛，所以一些其他的复杂操作这里就不说了。下面，针对上面几个功能，逐一进行分析。

#coding=utf-8
import requests

import bs4
import lxml


resp=requests.get('https://www.baidu.com') #请求百度首页
print(resp) #打印请求结果的状态码
print(resp.content) #打印请求到的网页源码

